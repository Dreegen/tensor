{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "import pandas as pd\n",
    "# produces a prediction model in the form of an ensemble of weak prediction models, typically decision tree\n",
    "import xgboost as xgb\n",
    "# the outcome (dependent variable) has only a limited number of possible values.\n",
    "# Logistic Regression is used when response variable is categorical in nature.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# A random forest is a meta estimator that fits a number of decision tree classifiers\n",
    "# on various sub-samples of the dataset and use averaging to improve the predictive\n",
    "# accuracy and control over-fitting.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# a discriminative classifier formally defined by a separating hyperplane.\n",
    "from sklearn.svm import SVC\n",
    "# displayd data\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>date</th>\n",
       "      <th>home_team</th>\n",
       "      <th>guest_team</th>\n",
       "      <th>score</th>\n",
       "      <th>home_score</th>\n",
       "      <th>guest_score</th>\n",
       "      <th>odds_1</th>\n",
       "      <th>odds_x</th>\n",
       "      <th>odds_2</th>\n",
       "      <th>explore_id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>ftr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Handbollsligan 2017/2018</td>\n",
       "      <td>14.03.2018</td>\n",
       "      <td>Alingsas</td>\n",
       "      <td>Savehof</td>\n",
       "      <td>26:29</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>1.38</td>\n",
       "      <td>9.57</td>\n",
       "      <td>3.78</td>\n",
       "      <td>ELL63qws</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Handbollsligan 2017/2018</td>\n",
       "      <td>14.03.2018</td>\n",
       "      <td>Hammarby</td>\n",
       "      <td>Helsingborg</td>\n",
       "      <td>26:31</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>1.29</td>\n",
       "      <td>10.20</td>\n",
       "      <td>4.64</td>\n",
       "      <td>hCKA23hm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Handbollsligan 2017/2018</td>\n",
       "      <td>14.03.2018</td>\n",
       "      <td>Karlskrona</td>\n",
       "      <td>Aranas</td>\n",
       "      <td>31:26</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>1.33</td>\n",
       "      <td>9.92</td>\n",
       "      <td>4.20</td>\n",
       "      <td>zyAF1N7g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Handbollsligan 2017/2018</td>\n",
       "      <td>14.03.2018</td>\n",
       "      <td>Kristianstad</td>\n",
       "      <td>Ricoh</td>\n",
       "      <td>30:22</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>1.01</td>\n",
       "      <td>23.45</td>\n",
       "      <td>19.68</td>\n",
       "      <td>nDhwLB8E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Handbollsligan 2017/2018</td>\n",
       "      <td>14.03.2018</td>\n",
       "      <td>Lugi</td>\n",
       "      <td>Guif</td>\n",
       "      <td>28:20</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.10</td>\n",
       "      <td>3.38</td>\n",
       "      <td>hEBnbl11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     season        date     home_team   guest_team  score  \\\n",
       "0  Handbollsligan 2017/2018  14.03.2018      Alingsas      Savehof  26:29   \n",
       "1  Handbollsligan 2017/2018  14.03.2018      Hammarby  Helsingborg  26:31   \n",
       "2  Handbollsligan 2017/2018  14.03.2018    Karlskrona       Aranas  31:26   \n",
       "3  Handbollsligan 2017/2018  14.03.2018  Kristianstad        Ricoh  30:22   \n",
       "4  Handbollsligan 2017/2018  14.03.2018          Lugi         Guif  28:20   \n",
       "\n",
       "   home_score  guest_score  odds_1  odds_x  odds_2 explore_id  outcome ftr  \n",
       "0          26           29    1.38    9.57    3.78   ELL63qws      NaN   2  \n",
       "1          26           31    1.29   10.20    4.64   hCKA23hm      NaN   2  \n",
       "2          31           26    1.33    9.92    4.20   zyAF1N7g      NaN   1  \n",
       "3          30           22    1.01   23.45   19.68   nDhwLB8E      NaN   1  \n",
       "4          28           20    1.46    9.10    3.38   hEBnbl11      NaN   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read data and drop redundant column.\n",
    "data = pd.read_csv('results.csv')\n",
    "\n",
    "# Preview data.\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the winrate for the home team?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of matches: 1666\n",
      "Number of features: 12\n",
      "Number of matches won by home team: 913\n",
      "Win rate of home team: 54.80%\n"
     ]
    }
   ],
   "source": [
    "# Total number of matches.\n",
    "n_matches = data.shape[0]\n",
    "\n",
    "# Calculate number of features. -1 because we are saving one as the target variable (win/lose/draw)\n",
    "n_features = data.shape[1] - 1\n",
    "\n",
    "# Calculate matches won by home team.\n",
    "n_homewins = len(data[data.ftr == '1'])\n",
    "\n",
    "# Calculate win rate for home team.\n",
    "win_rate = (float(n_homewins) / (n_matches)) * 100\n",
    "\n",
    "# Print results\n",
    "print(\"Total number of matches: {}\".format(n_matches))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Number of matches won by home team: {}\".format(n_homewins))\n",
    "print(\"Win rate of home team: {:.2f}%\".format(win_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into feature set and target variable\n",
    "#FTR = Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "data = data.dropna(subset=['odds_1', 'odds_x', 'odds_2'], how='any')\n",
    "X_all = data.drop(['season','date','ftr','home_team','guest_team','score','home_score','guest_score','explore_id','outcome'],1)\n",
    "y_all = data['ftr']\n",
    "\n",
    "# Standardising the data.\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#Center to the mean and component wise scale to unit variance.\n",
    "cols = [['odds_1','odds_x','odds_2']]\n",
    "for col in cols:\n",
    "    X_all[col] = scale(X_all[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (3 total features):\n",
      "['odds_1', 'odds_x', 'odds_2']\n"
     ]
    }
   ],
   "source": [
    "#we want continous vars that are integers for our input data, so lets remove any categorical vars\n",
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the football data and converts catagorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)\n",
    "                    \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print(\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>odds_1</th>\n",
       "      <th>odds_x</th>\n",
       "      <th>odds_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.466846</td>\n",
       "      <td>-0.522443</td>\n",
       "      <td>-0.032545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.515276</td>\n",
       "      <td>-0.303862</td>\n",
       "      <td>0.202692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.493752</td>\n",
       "      <td>-0.401009</td>\n",
       "      <td>0.082338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.665948</td>\n",
       "      <td>4.293279</td>\n",
       "      <td>4.316605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.423798</td>\n",
       "      <td>-0.685511</td>\n",
       "      <td>-0.141958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.402273</td>\n",
       "      <td>-0.845110</td>\n",
       "      <td>-0.180252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.776191</td>\n",
       "      <td>-0.518974</td>\n",
       "      <td>-0.683550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.165504</td>\n",
       "      <td>-1.008179</td>\n",
       "      <td>-0.456519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.923256</td>\n",
       "      <td>1.174162</td>\n",
       "      <td>-0.760139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.029103</td>\n",
       "      <td>-0.213654</td>\n",
       "      <td>-0.702697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.450703</td>\n",
       "      <td>-0.338557</td>\n",
       "      <td>-0.114605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.450703</td>\n",
       "      <td>-0.355905</td>\n",
       "      <td>-0.133752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.256983</td>\n",
       "      <td>-0.623060</td>\n",
       "      <td>-0.426430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.622899</td>\n",
       "      <td>1.382335</td>\n",
       "      <td>1.422642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.883813</td>\n",
       "      <td>-0.376722</td>\n",
       "      <td>-0.716374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.189650</td>\n",
       "      <td>-1.004709</td>\n",
       "      <td>-0.598755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.023722</td>\n",
       "      <td>-0.446113</td>\n",
       "      <td>-0.699962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.585231</td>\n",
       "      <td>0.802921</td>\n",
       "      <td>0.730608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.547563</td>\n",
       "      <td>0.067379</td>\n",
       "      <td>0.396899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.103552</td>\n",
       "      <td>-1.115735</td>\n",
       "      <td>-0.568667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.552944</td>\n",
       "      <td>0.091666</td>\n",
       "      <td>0.459812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.916100</td>\n",
       "      <td>-0.456522</td>\n",
       "      <td>-0.694491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.211174</td>\n",
       "      <td>-0.990831</td>\n",
       "      <td>-0.601491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.782460</td>\n",
       "      <td>0.220039</td>\n",
       "      <td>-0.732786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.507966</td>\n",
       "      <td>2.777090</td>\n",
       "      <td>-0.784757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.456084</td>\n",
       "      <td>-0.331618</td>\n",
       "      <td>-0.073575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.622899</td>\n",
       "      <td>1.538464</td>\n",
       "      <td>1.578555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.391511</td>\n",
       "      <td>-0.591834</td>\n",
       "      <td>-0.218547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.633661</td>\n",
       "      <td>1.739697</td>\n",
       "      <td>2.070912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.063263</td>\n",
       "      <td>-1.004709</td>\n",
       "      <td>-0.516696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>-0.472228</td>\n",
       "      <td>0.032683</td>\n",
       "      <td>-0.095457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>0.996817</td>\n",
       "      <td>-0.404479</td>\n",
       "      <td>-0.697227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>-0.402273</td>\n",
       "      <td>-0.695920</td>\n",
       "      <td>-0.188458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>0.673950</td>\n",
       "      <td>-0.609182</td>\n",
       "      <td>-0.672609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>0.786953</td>\n",
       "      <td>-0.508565</td>\n",
       "      <td>-0.683550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>0.227317</td>\n",
       "      <td>-0.688981</td>\n",
       "      <td>-0.615167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>-0.359224</td>\n",
       "      <td>-0.574486</td>\n",
       "      <td>-0.292400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>-0.300032</td>\n",
       "      <td>-0.723676</td>\n",
       "      <td>-0.355312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>-0.509895</td>\n",
       "      <td>-0.130385</td>\n",
       "      <td>0.134309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>0.469468</td>\n",
       "      <td>-0.435705</td>\n",
       "      <td>-0.658932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>-0.639042</td>\n",
       "      <td>1.819497</td>\n",
       "      <td>2.188531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>-0.407654</td>\n",
       "      <td>-0.491217</td>\n",
       "      <td>-0.196664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>-0.606755</td>\n",
       "      <td>0.896599</td>\n",
       "      <td>0.998669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>0.781572</td>\n",
       "      <td>-0.116507</td>\n",
       "      <td>-0.694491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>-0.429179</td>\n",
       "      <td>-0.487748</td>\n",
       "      <td>-0.180252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>-0.380749</td>\n",
       "      <td>-0.473870</td>\n",
       "      <td>-0.273253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>0.114314</td>\n",
       "      <td>-0.779189</td>\n",
       "      <td>-0.593285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>0.302653</td>\n",
       "      <td>-0.564078</td>\n",
       "      <td>-0.639785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>-0.531420</td>\n",
       "      <td>0.115952</td>\n",
       "      <td>0.183545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>1.777078</td>\n",
       "      <td>0.258204</td>\n",
       "      <td>-0.738256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>-0.143980</td>\n",
       "      <td>-0.945727</td>\n",
       "      <td>-0.489343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>2.159138</td>\n",
       "      <td>1.167223</td>\n",
       "      <td>-0.754668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>-0.160123</td>\n",
       "      <td>-0.782659</td>\n",
       "      <td>-0.492078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>-0.617518</td>\n",
       "      <td>1.194980</td>\n",
       "      <td>1.231170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>-0.332319</td>\n",
       "      <td>-0.532852</td>\n",
       "      <td>-0.349842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>-0.343081</td>\n",
       "      <td>-0.515504</td>\n",
       "      <td>-0.330694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>-0.644423</td>\n",
       "      <td>1.847253</td>\n",
       "      <td>2.462062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>-0.488371</td>\n",
       "      <td>-0.074872</td>\n",
       "      <td>-0.013398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>0.189650</td>\n",
       "      <td>-0.560608</td>\n",
       "      <td>-0.617902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>-0.445322</td>\n",
       "      <td>-0.359375</td>\n",
       "      <td>-0.144693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1433 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        odds_1    odds_x    odds_2\n",
       "0    -0.466846 -0.522443 -0.032545\n",
       "1    -0.515276 -0.303862  0.202692\n",
       "2    -0.493752 -0.401009  0.082338\n",
       "3    -0.665948  4.293279  4.316605\n",
       "4    -0.423798 -0.685511 -0.141958\n",
       "5    -0.402273 -0.845110 -0.180252\n",
       "6     0.776191 -0.518974 -0.683550\n",
       "7    -0.165504 -1.008179 -0.456519\n",
       "8     2.923256  1.174162 -0.760139\n",
       "9     1.029103 -0.213654 -0.702697\n",
       "10   -0.450703 -0.338557 -0.114605\n",
       "11   -0.450703 -0.355905 -0.133752\n",
       "13   -0.256983 -0.623060 -0.426430\n",
       "14   -0.622899  1.382335  1.422642\n",
       "15    0.883813 -0.376722 -0.716374\n",
       "16    0.189650 -1.004709 -0.598755\n",
       "17    1.023722 -0.446113 -0.699962\n",
       "18   -0.585231  0.802921  0.730608\n",
       "19   -0.547563  0.067379  0.396899\n",
       "20    0.103552 -1.115735 -0.568667\n",
       "21   -0.552944  0.091666  0.459812\n",
       "22    0.916100 -0.456522 -0.694491\n",
       "23    0.211174 -0.990831 -0.601491\n",
       "24    1.782460  0.220039 -0.732786\n",
       "25    7.507966  2.777090 -0.784757\n",
       "26   -0.456084 -0.331618 -0.073575\n",
       "27   -0.622899  1.538464  1.578555\n",
       "28   -0.391511 -0.591834 -0.218547\n",
       "29   -0.633661  1.739697  2.070912\n",
       "30   -0.063263 -1.004709 -0.516696\n",
       "...        ...       ...       ...\n",
       "1603 -0.472228  0.032683 -0.095457\n",
       "1612  0.996817 -0.404479 -0.697227\n",
       "1613 -0.402273 -0.695920 -0.188458\n",
       "1614  0.673950 -0.609182 -0.672609\n",
       "1615  0.786953 -0.508565 -0.683550\n",
       "1616  0.227317 -0.688981 -0.615167\n",
       "1617 -0.359224 -0.574486 -0.292400\n",
       "1618 -0.300032 -0.723676 -0.355312\n",
       "1619 -0.509895 -0.130385  0.134309\n",
       "1620  0.469468 -0.435705 -0.658932\n",
       "1621 -0.639042  1.819497  2.188531\n",
       "1622 -0.407654 -0.491217 -0.196664\n",
       "1623 -0.606755  0.896599  0.998669\n",
       "1624  0.781572 -0.116507 -0.694491\n",
       "1625 -0.429179 -0.487748 -0.180252\n",
       "1626 -0.380749 -0.473870 -0.273253\n",
       "1627  0.114314 -0.779189 -0.593285\n",
       "1628  0.302653 -0.564078 -0.639785\n",
       "1629 -0.531420  0.115952  0.183545\n",
       "1630  1.777078  0.258204 -0.738256\n",
       "1631 -0.143980 -0.945727 -0.489343\n",
       "1632  2.159138  1.167223 -0.754668\n",
       "1633 -0.160123 -0.782659 -0.492078\n",
       "1634 -0.617518  1.194980  1.231170\n",
       "1635 -0.332319 -0.532852 -0.349842\n",
       "1636 -0.343081 -0.515504 -0.330694\n",
       "1637 -0.644423  1.847253  2.462062\n",
       "1638 -0.488371 -0.074872 -0.013398\n",
       "1639  0.189650 -0.560608 -0.617902\n",
       "1647 -0.445322 -0.359375 -0.144693\n",
       "\n",
       "[1433 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labels:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       2\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "5       2\n",
       "6       2\n",
       "7       1\n",
       "8       2\n",
       "9       2\n",
       "10      1\n",
       "11      1\n",
       "13      2\n",
       "14      1\n",
       "15      X\n",
       "16      X\n",
       "17      2\n",
       "18      1\n",
       "19      1\n",
       "20      2\n",
       "21      1\n",
       "22      2\n",
       "23      2\n",
       "24      2\n",
       "25      1\n",
       "26      1\n",
       "27      1\n",
       "28      1\n",
       "29      1\n",
       "30      1\n",
       "       ..\n",
       "1603    1\n",
       "1612    2\n",
       "1613    2\n",
       "1614    2\n",
       "1615    2\n",
       "1616    2\n",
       "1617    1\n",
       "1618    2\n",
       "1619    1\n",
       "1620    2\n",
       "1621    1\n",
       "1622    1\n",
       "1623    1\n",
       "1624    2\n",
       "1625    1\n",
       "1626    X\n",
       "1627    2\n",
       "1628    1\n",
       "1629    1\n",
       "1630    2\n",
       "1631    X\n",
       "1632    2\n",
       "1633    2\n",
       "1634    1\n",
       "1635    1\n",
       "1636    2\n",
       "1637    1\n",
       "1638    1\n",
       "1639    1\n",
       "1647    2\n",
       "Name: ftr, Length: 1433, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the feature information by printing the first five rows\n",
    "print(\"\\nFeature values:\")\n",
    "display(X_all)\n",
    "\n",
    "print(\"\\nLabels:\")\n",
    "display(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffle and split the dataset into training and testing set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "                                                    test_size = 50,\n",
    "                                                    random_state = 2,\n",
    "                                                    stratify = y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for measuring training time\n",
    "from time import time \n",
    "# F1 score (also F-score or F-measure) is a measure of a test's accuracy. \n",
    "#It considers both the precision p and the recall r of the test to compute \n",
    "#the score: p is the number of correct positive results divided by the number of \n",
    "#all positive results, and r is the number of correct positive results divided by \n",
    "#the number of positive results that should have been returned. The F1 score can be \n",
    "#interpreted as a weighted average of the precision and recall, where an F1 score \n",
    "#reaches its best value at 1 and worst at 0.\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    \n",
    "    end = time()\n",
    "    # Print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    \n",
    "    return f1_score(target, y_pred, average=None), sum(target == y_pred) / float(len(y_pred))\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    f1, acc = predict_labels(clf, X_train, y_train)\n",
    "    print(f1, acc)\n",
    "    \n",
    "    f1, acc = predict_labels(clf, X_test, y_test)\n",
    "    print(f1, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a LogisticRegression using a training set size of 1383. . .\n",
      "Trained model in 0.0085 seconds\n",
      "Made predictions in 0.0015 seconds.\n",
      "[0.76317383 0.61966236 0.        ] 0.6811279826464208\n",
      "Made predictions in 0.0005 seconds.\n",
      "[0.77419355 0.64705882 0.        ] 0.7\n",
      "\n",
      "Training a SVC using a training set size of 1383. . .\n",
      "Trained model in 0.0461 seconds\n",
      "Made predictions in 0.0208 seconds.\n",
      "[0.7656066  0.61041667 0.        ] 0.6818510484454086\n",
      "Made predictions in 0.0012 seconds.\n",
      "[0.76190476 0.60606061 0.        ] 0.68\n",
      "\n",
      "Training a XGBClassifier using a training set size of 1383. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hallberg/.virtualenvs/tensor/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/hallberg/.virtualenvs/tensor/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/hallberg/.virtualenvs/tensor/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/hallberg/.virtualenvs/tensor/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/hallberg/.virtualenvs/tensor/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/hallberg/.virtualenvs/tensor/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/hallberg/.virtualenvs/tensor/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 0.1302 seconds\n",
      "Made predictions in 0.0101 seconds.\n",
      "[0.79207921 0.69097889 0.        ] 0.7230657989877078\n",
      "Made predictions in 0.0011 seconds.\n",
      "[0.79365079 0.66666667 0.        ] 0.72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the three models (XGBoost is initialized later)\n",
    "clf_A = LogisticRegression(random_state = 42)\n",
    "clf_B = SVC(random_state = 912, kernel='rbf')\n",
    "#Boosting refers to this general problem of producing a very accurate prediction rule \n",
    "#by combining rough and moderately inaccurate rules-of-thumb\n",
    "clf_C = xgb.XGBClassifier(seed = 82)\n",
    "\n",
    "train_predict(clf_A, X_train, y_train, X_test, y_test,)\n",
    "print('')\n",
    "train_predict(clf_B, X_train, y_train, X_test, y_test)\n",
    "print('')\n",
    "train_predict(clf_C, X_train, y_train, X_test, y_test)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c9eadd9b4ef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# TODO: Perform grid search on the classifier using the f1_scorer as the scoring method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m grid_obj = GridSearchCV(clf,\n\u001b[0m\u001b[1;32m     26\u001b[0m                         \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf1_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                         \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Import 'GridSearchCV' and 'make_scorer'\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune\n",
    "parameters = { 'learning_rate' : [0.1],\n",
    "               'n_estimators' : [40],\n",
    "               'max_depth': [3],\n",
    "               'min_child_weight': [3],\n",
    "               'gamma':[0.4],\n",
    "               'subsample' : [0.8],\n",
    "               'colsample_bytree' : [0.8],\n",
    "               'scale_pos_weight' : [1],\n",
    "               'reg_alpha':[1e-5]\n",
    "             }  \n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = xgb.XGBClassifier(seed=2)\n",
    "\n",
    "# TODO: Make an f1 scoring function using 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score,pos_label='1')\n",
    "\n",
    "# TODO: Perform grid search on the classifier using the f1_scorer as the scoring method\n",
    "grid_obj = GridSearchCV(clf,\n",
    "                        scoring=f1_scorer,\n",
    "                        param_grid=parameters,\n",
    "                        cv=5)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_obj = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "print(clf)\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "f1, acc = predict_labels(clf, X_train, y_train)\n",
    "print(\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
    "    \n",
    "f1, acc = predict_labels(clf, X_test, y_test)\n",
    "print(\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
